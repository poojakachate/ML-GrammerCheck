{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define your RNN or transformer model\n",
        "class MisusedWordDetector(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
        "        super(MisusedWordDetector, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        output, _ = self.rnn(embedded)\n",
        "        output = self.fc(output[:, -1, :])  # Take only the last output in the sequence\n",
        "        return output\n",
        "\n",
        "# Example data (replace with your own dataset)\n",
        "sentences = [\"There they saw something extraordinary, far exceeding what they knew.\",\n",
        "             \"Their knowledge of those facts was incomplete.\",\n",
        "             \"They're going to learn something new from the ML course.\",\n",
        "             \"They're they saw something extraordinary, far exceeding what they knew.\",\n",
        "             \"There knowledge of those facts was incomplete.\",\n",
        "             \"Their going to learn something new from the ML course.\",\n",
        "             \"There they discovered an ancient artifact, surpassing all expectations.\",\n",
        "             \"Their understanding of the subject matter was limited.\",\n",
        "             \"They're exploring innovative concepts in the field of artificial intelligence.\",\n",
        "             \"They're convinced they saw something extraordinary, beyond their comprehension.\",\n",
        "             \"There exists a gap in their knowledge regarding these complex facts.\",\n",
        "             \"Their pursuit of learning is leading them to new insights in the ML course.\",\n",
        "             \"There was a moment of silence as they absorbed the breathtaking view.\",\n",
        "             \"Their expertise in the subject matter was apparent in their insightful analysis.\",\n",
        "             \"They're eagerly anticipating the upcoming advancements in technology.\",\n",
        "             \"They're certain they witnessed something extraordinary, beyond ordinary comprehension.\",\n",
        "             \"There seems to be a discrepancy in their understanding of these intricate details.\",\n",
        "             \"Their commitment to learning is driving them towards excellence in the ML course.\",\n",
        "             \"There, amidst the chaos, they found a sense of calm and clarity.\",\n",
        "             \"Their meticulous approach to problem-solving sets them apart in their field.\",\n",
        "             \"They're determined to gain new insights and skills from the evolving world of AI.\",\n",
        "             \"They're sharing their knowledge with others to foster a collaborative learning environment.\"\n",
        "             ]\n",
        "\n",
        "labels = [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]  # 0: Correct, 1: Incorrect\n",
        "\n",
        "# Tokenize sentences and convert to numerical representations\n",
        "vocab = set(word for sentence in sentences for word in sentence.split())\n",
        "word_to_index = {word: idx for idx, word in enumerate(vocab)}\n",
        "indexed_sentences = [[word_to_index[word] for word in sentence.split()] for sentence in sentences]\n",
        "\n",
        "# Ensure consistent lengths of input sequences\n",
        "max_len = max(len(sentence) for sentence in indexed_sentences)\n",
        "padded_sentences = [sentence + [0] * (max_len - len(sentence)) for sentence in indexed_sentences]\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X = torch.tensor(padded_sentences, dtype=torch.long)\n",
        "y = torch.tensor(labels, dtype=torch.float)\n",
        "\n",
        "# Ensure consistent lengths of input sequences\n",
        "max_len = max(len(sentence) for sentence in indexed_sentences)\n",
        "padded_sentences = [sentence + [0] * (max_len - len(sentence)) for sentence in indexed_sentences]\n",
        "\n",
        "# Check and adjust the lengths if necessary\n",
        "if X.size(0) != len(y):\n",
        "    num_samples = min(X.size(0), len(y))\n",
        "    X = X[:num_samples]\n",
        "    y = y[:num_samples]\n",
        "\n",
        "# Use train_test_split for consistent splitting\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Ensure that y_train and y_test have the correct size\n",
        "y_train = y_train.unsqueeze(1)  # Add unsqueeze(1) to match output size\n",
        "y_test = y_test.unsqueeze(1)\n",
        "\n",
        "# Create DataLoader for training\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "\n",
        "# Create DataLoader for testing\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
        "\n",
        "# Instantiate the model, loss function, and optimizer\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 50\n",
        "hidden_dim = 20\n",
        "output_dim = 1\n",
        "model = MisusedWordDetector(vocab_size, embedding_dim, hidden_dim, output_dim)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Evaluation loop\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(X_test)\n",
        "    test_loss = criterion(test_outputs, y_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "predicted_labels = (torch.sigmoid(test_outputs) >= 0.5).float()  # Applying threshold\n",
        "correct_predictions = (predicted_labels == y_test).float()\n",
        "test_accuracy = correct_predictions.mean().item()\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Test the inference function\n",
        "test_sentence = \"They're they saw something extraordinary, far exceeding what they knew.\"\n",
        "indexed_test_sentence = [word_to_index[word] for word in test_sentence.split()]\n",
        "padded_test_sentence = indexed_test_sentence + [0] * (max_len - len(indexed_test_sentence))\n",
        "input_tensor = torch.tensor([padded_test_sentence], dtype=torch.long)\n",
        "with torch.no_grad():\n",
        "    output = model(input_tensor)\n",
        "prediction = torch.sigmoid(output.squeeze()).item()\n",
        "\n",
        "print(f\"Is the test sentence misused? {'Yes' if prediction < 0.5 else 'No'}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhwH0QGIm2Yy",
        "outputId": "b43cfde0-fce0-460c-8ff2-bb20d720fe29"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 100.00%\n",
            "Is the test sentence misused? Yes\n"
          ]
        }
      ]
    }
  ]
}